{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMY+xrJZZMTkgNFScDqaNmv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Avani Agarwal\n","\n","102303745\n","\n","Assignment-4"],"metadata":{"id":"_huKOQMDZlh3"}},{"cell_type":"markdown","source":["Q1. Scrape Books from Books to Scrape"],"metadata":{"id":"IKHYZWwSceM7"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","base_url = \"https://books.toscrape.com/catalogue/page-{}.html\"\n","books = []\n","\n","page = 1\n","while True:\n","    url = base_url.format(page)\n","    response = requests.get(url)\n","    if response.status_code != 200:\n","        break\n","\n","    soup = BeautifulSoup(response.text, \"html.parser\")\n","    articles = soup.find_all(\"article\", class_=\"product_pod\")\n","    if not articles:\n","        break\n","\n","    for book in articles:\n","        title = book.h3.a[\"title\"]\n","        price = book.find(\"p\", class_=\"price_color\").text\n","        availability = book.find(\"p\", class_=\"instock availability\").text.strip()\n","        star_rating = book.p[\"class\"][1]\n","\n","        books.append({\n","            \"Title\": title,\n","            \"Price\": price,\n","            \"Availability\": availability,\n","            \"Star Rating\": star_rating\n","        })\n","\n","    page += 1\n","\n","df_books = pd.DataFrame(books)\n","df_books.to_csv(\"books.csv\", index=False)\n","print(\"Scraped\", len(df_books), \"books and saved to books.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PrVAMno_bxa2","executionInfo":{"status":"ok","timestamp":1756749868954,"user_tz":-330,"elapsed":40230,"user":{"displayName":"AVANI AGARWAL","userId":"05443345034255352571"}},"outputId":"01263470-49ac-4488-e8d8-5a56b2d145d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Scraped 1000 books and saved to books.csv\n"]}]},{"cell_type":"markdown","source":["Q2. Scrape IMDB Top 250 Movies"],"metadata":{"id":"oa7odP5AchEe"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","url = \"https://www.imdb.com/chart/top/\"\n","headers = {\"User-Agent\": \"Mozilla/5.0\"}\n","response = requests.get(url, headers=headers)\n","soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","movies = []\n","rows = soup.select(\"tbody.lister-list tr\")\n","\n","for row in rows:\n","    rank = int(row.find(\"td\", class_=\"titleColumn\").get_text(strip=True).split(\".\")[0])\n","    title = row.find(\"td\", class_=\"titleColumn a\").get_text(strip=True)\n","    year = int(row.find(\"td\", class_=\"titleColumn span\").get_text(strip=True).strip(\"()\"))\n","    rating = float(row.find(\"td\", class_=\"ratingColumn imdbRating strong\").get_text(strip=True))\n","\n","    movies.append({\n","        \"Rank\": rank,\n","        \"Movie Title\": title,\n","        \"Year\": year,\n","        \"IMDB Rating\": rating\n","    })\n","\n","df_movies = pd.DataFrame(movies)\n","df_movies.to_csv(\"imdb_top250.csv\", index=False)\n","print(\"Scraped\", len(df_movies), \"movies and saved to imdb_top250.csv\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X1FMrUutd3eg","executionInfo":{"status":"ok","timestamp":1756750123718,"user_tz":-330,"elapsed":4439,"user":{"displayName":"AVANI AGARWAL","userId":"05443345034255352571"}},"outputId":"d7bf78ab-6405-4708-a59b-275297b22bbd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Scraped 0 movies and saved to imdb_top250.csv\n"]}]},{"cell_type":"markdown","source":["Q3. Scrape Weather for Top Cities"],"metadata":{"id":"vonK6uwzcluG"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","url = \"https://www.timeanddate.com/weather/india/new-delhi/historic\"\n","headers = {\"User-Agent\": \"Mozilla/5.0\"}\n","res = requests.get(url, headers=headers)\n","soup = BeautifulSoup(res.text, \"html.parser\")\n","\n","table = soup.find(\"table\", id=\"wt-his\")\n","if table:\n","    data = []\n","    for tr in table.find(\"tbody\").find_all(\"tr\"):\n","        time_label = tr.find(\"th\").get_text(strip=True)\n","        tds = tr.find_all(\"td\")\n","        data.append({\n","            \"Time\": time_label,\n","            \"Temperature\": tds[1].get_text(strip=True),\n","            \"Weather\": tds[2].get_text(strip=True),\n","            \"Wind\": tds[3].get_text(strip=True),\n","            \"Humidity\": tds[5].get_text(strip=True),\n","            \"Barometer\": tds[6].get_text(strip=True),\n","            \"Visibility\": tds[7].get_text(strip=True),\n","        })\n","    df = pd.DataFrame(data)\n","    df.to_csv(\"historic_weather_delhi.csv\", index=False)\n","    print(\"Scraped historical weather:\", len(df), \"records\")\n","else:\n","    print(\"Historic weather table not found!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lI8dAXJ5coQG","executionInfo":{"status":"ok","timestamp":1756750270263,"user_tz":-330,"elapsed":292,"user":{"displayName":"AVANI AGARWAL","userId":"05443345034255352571"}},"outputId":"72cb2965-9742-42dc-ba2c-7346beb6735b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Scraped historical weather: 8 records\n"]}]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","url = \"https://www.timeanddate.com/weather/\"\n","headers = {\"User-Agent\": \"Mozilla/5.0\"}\n","res = requests.get(url, headers=headers)\n","soup = BeautifulSoup(res.text, \"html.parser\")\n","\n","cities = []\n","table = soup.select_one(\"table.zebra.tb-wt\")\n","\n","if table:\n","    for row in table.select(\"tbody tr\"):\n","        cols = row.find_all(\"td\")\n","        if len(cols) >= 3:\n","            city = cols[0].get_text(strip=True)\n","            temp = cols[1].get_text(strip=True)\n","            condition = cols[2].get_text(strip=True)\n","\n","            cities.append({\n","                \"City Name\": city,\n","                \"Temperature\": temp,\n","                \"Weather Condition\": condition\n","            })\n","\n","df_weather = pd.DataFrame(cities)\n","df_weather.to_csv(\"weather.csv\", index=False)\n","print(\" Scraped\", len(df_weather), \"cities and saved to weather.csv\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n_mY5O4zF1jx","executionInfo":{"status":"ok","timestamp":1756978717305,"user_tz":-330,"elapsed":374,"user":{"displayName":"AVANI AGARWAL","userId":"05443345034255352571"}},"outputId":"5950d941-9f14-4c5a-8d63-339c8e930244"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":[" Scraped 0 cities and saved to weather.csv\n"]}]}]}