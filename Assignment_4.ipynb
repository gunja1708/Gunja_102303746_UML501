{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Scrape Books from Books to Scrape"
      ],
      "metadata": {
        "id": "IKHYZWwSceM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "base_url = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
        "books = []\n",
        "\n",
        "page = 1\n",
        "while True:\n",
        "    url = base_url.format(page)\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        break\n",
        "\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    articles = soup.find_all(\"article\", class_=\"product_pod\")\n",
        "    if not articles:\n",
        "        break\n",
        "\n",
        "    for book in articles:\n",
        "        title = book.h3.a[\"title\"]\n",
        "        price = book.find(\"p\", class_=\"price_color\").text\n",
        "        availability = book.find(\"p\", class_=\"instock availability\").text.strip()\n",
        "        star_rating = book.p[\"class\"][1]\n",
        "\n",
        "        books.append({\n",
        "            \"Title\": title,\n",
        "            \"Price\": price,\n",
        "            \"Availability\": availability,\n",
        "            \"Star Rating\": star_rating\n",
        "        })\n",
        "\n",
        "    page += 1\n",
        "\n",
        "df_books = pd.DataFrame(books)\n",
        "df_books.to_csv(\"books.csv\", index=False)\n",
        "print(\"Scraped\", len(df_books), \"books and saved to books.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrVAMno_bxa2",
        "outputId": "01263470-49ac-4488-e8d8-5a56b2d145d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped 1000 books and saved to books.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. Scrape IMDB Top 250 Movies"
      ],
      "metadata": {
        "id": "oa7odP5AchEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://www.imdb.com/chart/top/\"\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "response = requests.get(url, headers=headers)\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "movies = []\n",
        "rows = soup.select(\"tbody.lister-list tr\")\n",
        "\n",
        "for row in rows:\n",
        "    rank = int(row.find(\"td\", class_=\"titleColumn\").get_text(strip=True).split(\".\")[0])\n",
        "    title = row.find(\"td\", class_=\"titleColumn a\").get_text(strip=True)\n",
        "    year = int(row.find(\"td\", class_=\"titleColumn span\").get_text(strip=True).strip(\"()\"))\n",
        "    rating = float(row.find(\"td\", class_=\"ratingColumn imdbRating strong\").get_text(strip=True))\n",
        "\n",
        "    movies.append({\n",
        "        \"Rank\": rank,\n",
        "        \"Movie Title\": title,\n",
        "        \"Year\": year,\n",
        "        \"IMDB Rating\": rating\n",
        "    })\n",
        "\n",
        "df_movies = pd.DataFrame(movies)\n",
        "df_movies.to_csv(\"imdb_top250.csv\", index=False)\n",
        "print(\"Scraped\", len(df_movies), \"movies and saved to imdb_top250.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1FMrUutd3eg",
        "outputId": "d7bf78ab-6405-4708-a59b-275297b22bbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped 0 movies and saved to imdb_top250.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Scrape Weather for Top Cities"
      ],
      "metadata": {
        "id": "vonK6uwzcluG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://www.timeanddate.com/weather/india/new-delhi/historic\"\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "res = requests.get(url, headers=headers)\n",
        "soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "\n",
        "table = soup.find(\"table\", id=\"wt-his\")\n",
        "if table:\n",
        "    data = []\n",
        "    for tr in table.find(\"tbody\").find_all(\"tr\"):\n",
        "        time_label = tr.find(\"th\").get_text(strip=True)\n",
        "        tds = tr.find_all(\"td\")\n",
        "        data.append({\n",
        "            \"Time\": time_label,\n",
        "            \"Temperature\": tds[1].get_text(strip=True),\n",
        "            \"Weather\": tds[2].get_text(strip=True),\n",
        "            \"Wind\": tds[3].get_text(strip=True),\n",
        "            \"Humidity\": tds[5].get_text(strip=True),\n",
        "            \"Barometer\": tds[6].get_text(strip=True),\n",
        "            \"Visibility\": tds[7].get_text(strip=True),\n",
        "        })\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(\"historic_weather_delhi.csv\", index=False)\n",
        "    print(\"Scraped historical weather:\", len(df), \"records\")\n",
        "else:\n",
        "    print(\"Historic weather table not found!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lI8dAXJ5coQG",
        "outputId": "72cb2965-9742-42dc-ba2c-7346beb6735b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped historical weather: 8 records\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://www.timeanddate.com/weather/\"\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "res = requests.get(url, headers=headers)\n",
        "soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "\n",
        "cities = []\n",
        "table = soup.select_one(\"table.zebra.tb-wt\")\n",
        "\n",
        "if table:\n",
        "    for row in table.select(\"tbody tr\"):\n",
        "        cols = row.find_all(\"td\")\n",
        "        if len(cols) >= 3:\n",
        "            city = cols[0].get_text(strip=True)\n",
        "            temp = cols[1].get_text(strip=True)\n",
        "            condition = cols[2].get_text(strip=True)\n",
        "\n",
        "            cities.append({\n",
        "                \"City Name\": city,\n",
        "                \"Temperature\": temp,\n",
        "                \"Weather Condition\": condition\n",
        "            })\n",
        "\n",
        "df_weather = pd.DataFrame(cities)\n",
        "df_weather.to_csv(\"weather.csv\", index=False)\n",
        "print(\" Scraped\", len(df_weather), \"cities and saved to weather.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_mY5O4zF1jx",
        "outputId": "5950d941-9f14-4c5a-8d63-339c8e930244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Scraped 0 cities and saved to weather.csv\n"
          ]
        }
      ]
    }
  ]
}